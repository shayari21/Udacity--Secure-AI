{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shayari21/Udacity--Secure-AI/blob/master/Training_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1n4NbHvJtrM",
        "colab_type": "text"
      },
      "source": [
        "# Training Neural Networks\n",
        "\n",
        "First the NN we have constructed isn't trained yet. It cannot predict the probability of certain classes and thus considers equal probabilities for all cases. So thus we can conclude by saying that training a NN is required to get appropriate results.\n",
        "\n",
        "To find if the prediction is correct, we try to calculate a loss function which basically is the mean squared loss.\n",
        "\n",
        "## Gradient Descent and Back Propagation\n",
        "To minimise the loss, we use the technique known as gradient decsent. It basically points to that direction where the loss decreases or the slope gradient is maximum. We use **back propagation** for training NN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OToNZdGlSJlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),\n",
        "                                                                           (0.5,)),])\n",
        "trainset=datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True, transform= transform)\n",
        "trainloader= torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oNkJz1TTI9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c592a64-6ba6-447a-b3e0-0de43b3e213e"
      },
      "source": [
        "# Building Feed Forward Network and calculating Loss\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10))\n",
        "\n",
        "\n",
        "criterion =  nn. CrossEntropyLoss()\n",
        "images,labels= next(iter(trainloader))\n",
        "\n",
        "images= images.view(images.shape[0],-1)\n",
        "logits= model(images)\n",
        "loss = criterion(logits,labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3012, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq1OsigrW5J_",
        "colab_type": "text"
      },
      "source": [
        "we can use nn.LogSoftmax or F.log_softmax  to model it will log softmax output and get actual probabilities by torch.exp(output).\n",
        "\n",
        "We here calculate the error using nn.NLLLoss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cje_trqgXMmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "51e6e283-e549-4bbd-c7ea-75db0614f49d"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "criterion =  nn. NLLLoss()\n",
        "images,labels= next(iter(trainloader))\n",
        "\n",
        "images= images.view(images.shape[0],-1)\n",
        "logits= model(images)\n",
        "loss = criterion(logits,labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3222, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpKPTJI4ZTjP",
        "colab_type": "text"
      },
      "source": [
        "pytorch has  a module called **Autograd** which keeps track of the operation the user does and displayes them when the user asks to. We can switch it off as well.\n",
        "\n",
        "the gradients are calculated wrt to some variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB91E65naYQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(2,2,requires_grade=True)\n",
        "print(x)\n",
        "y = x**2\n",
        "z=y.mean\n",
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqIQa1mbDHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "e560d47b-715b-4419-ced1-62cb67e610bf"
      },
      "source": [
        "# using it in NN\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "criterion =  nn. NLLLoss()\n",
        "images,labels= next(iter(trainloader))\n",
        "\n",
        "images= images.view(images.shape[0],-1)\n",
        "logits= model(images)\n",
        "loss = criterion(logits,labels)\n",
        "\n",
        "print(\"Before Bck:\",model[0].weight.grad)\n",
        "loss.backward()\n",
        "print(\"After back:\", model[0].weight.grad)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Bck: None\n",
            "After back: tensor([[ 2.6282e-03,  2.6282e-03,  2.6282e-03,  ...,  2.6282e-03,\n",
            "          2.6282e-03,  2.6282e-03],\n",
            "        [-1.1559e-03, -1.1559e-03, -1.1559e-03,  ..., -1.1559e-03,\n",
            "         -1.1559e-03, -1.1559e-03],\n",
            "        [ 2.4392e-03,  2.4392e-03,  2.4392e-03,  ...,  2.4392e-03,\n",
            "          2.4392e-03,  2.4392e-03],\n",
            "        ...,\n",
            "        [-1.4205e-03, -1.4205e-03, -1.4205e-03,  ..., -1.4205e-03,\n",
            "         -1.4205e-03, -1.4205e-03],\n",
            "        [-2.0766e-04, -2.0766e-04, -2.0766e-04,  ..., -2.0766e-04,\n",
            "         -2.0766e-04, -2.0766e-04],\n",
            "        [ 3.9423e-05,  3.9423e-05,  3.9423e-05,  ...,  3.9423e-05,\n",
            "          3.9423e-05,  3.9423e-05]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx_nKiBqducO",
        "colab_type": "text"
      },
      "source": [
        "#Training!\n",
        "\n",
        "Using optim module of torch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNgDlnWopNCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c3e4bc4b-e078-4eb6-bc20-3f8af37fa0e0"
      },
      "source": [
        "from torch import optim\n",
        "optimizer= optim.SGD(model.parameters(),lr=0.01)\n",
        "\n",
        "\n",
        "print ('Initial weights -', model[0].weight)\n",
        "\n",
        "images, labels= next(iter(trainloader))\n",
        "images.resize_(64,784)\n",
        "\n",
        "optimizer.zero_grad() # Clears old gradients- VERY IMPORTANT\n",
        "\n",
        "output=model.forward(images)\n",
        "loss= criterion(output,labels)\n",
        "loss.backward()\n",
        "print(\"Gradient -\",model[0].weight.grad)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights - Parameter containing:\n",
            "tensor([[ 0.0098,  0.0087, -0.0070,  ...,  0.0335,  0.0150,  0.0325],\n",
            "        [ 0.0081, -0.0270,  0.0135,  ..., -0.0288, -0.0058, -0.0119],\n",
            "        [-0.0108,  0.0004,  0.0320,  ...,  0.0213,  0.0070, -0.0161],\n",
            "        ...,\n",
            "        [-0.0091,  0.0233,  0.0271,  ...,  0.0088, -0.0228, -0.0226],\n",
            "        [-0.0196, -0.0241,  0.0256,  ...,  0.0118, -0.0292,  0.0024],\n",
            "        [-0.0204, -0.0056,  0.0226,  ..., -0.0205, -0.0016,  0.0053]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0034,  0.0034,  0.0034,  ...,  0.0034,  0.0034,  0.0034],\n",
            "        [ 0.0049,  0.0049,  0.0049,  ...,  0.0049,  0.0049,  0.0049],\n",
            "        [ 0.0027,  0.0027,  0.0027,  ...,  0.0027,  0.0027,  0.0027],\n",
            "        ...,\n",
            "        [-0.0025, -0.0025, -0.0025,  ..., -0.0025, -0.0025, -0.0025],\n",
            "        [-0.0001, -0.0001, -0.0001,  ..., -0.0001, -0.0001, -0.0001],\n",
            "        [ 0.0011,  0.0011,  0.0011,  ...,  0.0011,  0.0011,  0.0011]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfoh0RJFql8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "9d7f074c-4a20-4a12-d3ed-2b0685c64941"
      },
      "source": [
        "optimizer.step()\n",
        "print('Updated weights -', model[0].weight)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights - Parameter containing:\n",
            "tensor([[ 0.0097,  0.0086, -0.0071,  ...,  0.0334,  0.0150,  0.0324],\n",
            "        [ 0.0081, -0.0270,  0.0135,  ..., -0.0289, -0.0059, -0.0120],\n",
            "        [-0.0108,  0.0004,  0.0320,  ...,  0.0212,  0.0069, -0.0161],\n",
            "        ...,\n",
            "        [-0.0091,  0.0233,  0.0272,  ...,  0.0088, -0.0227, -0.0226],\n",
            "        [-0.0196, -0.0241,  0.0256,  ...,  0.0118, -0.0292,  0.0024],\n",
            "        [-0.0204, -0.0056,  0.0226,  ..., -0.0205, -0.0016,  0.0053]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db923329-1d54-40c5-b209-bc0a057e91be",
        "id": "nwEt2zF2zbRY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "## COMPLETE MODEL\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "criterion =  nn. NLLLoss()\n",
        "optimizer= optim.SGD(model.parameters(),lr=0.03)\n",
        "\n",
        "epochs=5\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    \n",
        "    images = images.view(images.shape[0],-1)\n",
        "    optimizer.zero_grad() # Clears old gradients- VERY IMPORTANT\n",
        "\n",
        "    output=model.forward(images)\n",
        "    loss= criterion(output,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    \n",
        "  else:\n",
        "     \n",
        "     print(f\"Training loss:{running_loss/len(trainloader)}\")\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss:0.6049599748557565\n",
            "Training loss:0.27909948513197747\n",
            "Training loss:0.21470904898748341\n",
            "Training loss:0.17165970954813684\n",
            "Training loss:0.14449586481380183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se8DhCY9zwX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "1217d9d2-02b9-4ef3-8d31-c1ce7daec5e8"
      },
      "source": [
        "!pip install helper\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: helper in /usr/local/lib/python3.6/dist-packages (2.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from helper) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_qIZloG0gar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "248e6deb-9b80-4202-8630-3cbe1faf43a4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-06 12:44:53--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2813 (2.7K) [text/plain]\n",
            "Saving to: ‘helper.py’\n",
            "\n",
            "\rhelper.py             0%[                    ]       0  --.-KB/s               \rhelper.py           100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-06 12:44:53 (83.3 MB/s) - ‘helper.py’ saved [2813/2813]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Ul5K9MzyeC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "0058f8b0-4d0f-4461-cb6e-44fc47f7fe93"
      },
      "source": [
        "%matplotlib inline\n",
        "import helper.py as helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c2f43202f5ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper.py'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}