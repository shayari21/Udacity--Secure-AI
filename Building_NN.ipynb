{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shayari21/Udacity--Secure-AI/blob/master/Building_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aunLrZNS3Ho1",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks in Pytorch\n",
        "\n",
        "Here we use the MNIST datasets available in the *torchvision* package. So MNIST consists of various handwritten visual images and we later on create a neural network which recognises those images.\n",
        "\n",
        "We import MNIST package as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7kU-KY138dT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "895b2454-4eca-487d-9048-01bf026135a7"
      },
      "source": [
        "!pip install torchvision\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWybultF5Jgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ofZ8aib6FCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "402a4a99-e5a2-453f-f1c4-dfc42abf0a7f"
      },
      "source": [
        "# Normalising data\n",
        "transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),\n",
        "                                                                           (0.5,0.5,0.5)),])\n",
        "trainset=datasets.MNIST('MNIST_data/',download=True,train=True, transform= transform)\n",
        "trainloader= torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8557964.13it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 136951.54it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2249199.38it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51319.80it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx73HWM_8aoy",
        "colab_type": "text"
      },
      "source": [
        "We now check what we have downloaded by iterating it using *iter(trainloader)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TL8MBZ-8Fkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5eaba65e-7d5a-49d1-dc6f-66de4fb3a853"
      },
      "source": [
        "# Normalising data\n",
        "transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),\n",
        "                                                                           (0.5,)),])\n",
        "trainset=datasets.MNIST('MNIST_data/',download=True,train=True, transform= transform)\n",
        "trainloader= torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)\n",
        "dataiter= iter(trainloader)\n",
        "images, labels=dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape) #(batch size, color channel, pixel, pixel)\n",
        "print(labels.shape)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erKaOuGP_BrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "ce3d6172-90b5-458e-cfa4-532ecface3ed"
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(),cmap='Greys_r');"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBThB4Ii/EBQ/wfihZC8DNzW9QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBEqwlAaCgKp",
        "colab_type": "text"
      },
      "source": [
        "Now we flatten the image to 28X28=784 (converting a 2d to 1d), thus the new images is of size (64,784). Thus NN will have 784 input units , 256 hidden units and 10 output units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5-KTM0eC0Co",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2322
        },
        "outputId": "2c04c0b0-e8fa-4bab-f5f6-bca9ebb25346"
      },
      "source": [
        "# Flattening images\n",
        "\n",
        "def activation(x):\n",
        "  return 1/(1+torch.exp(-x))\n",
        "\n",
        "inputs= images.view(images.shape[0],-1) ## -1 to create the 1d\n",
        "\n",
        "w1=torch.randn(784,256)\n",
        "b1= torch.randn(256)\n",
        "\n",
        "w2= torch.randn(256,10)\n",
        "b2= torch.randn(10)\n",
        "\n",
        "h = activation(torch.mm(inputs,w1)+b1)\n",
        "\n",
        "out= torch.mm(h,w2)+b2\n",
        "print(out.shape)\n",
        "print(out)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([[ 4.8200e+00,  1.4900e-01, -1.3551e+01, -1.4280e+01, -2.3578e+00,\n",
            "          1.1601e+01, -6.3677e+00, -1.3442e+01,  1.1009e+01, -9.9163e+00],\n",
            "        [-9.5477e+00, -2.9735e+00, -4.9223e+00, -4.1817e-01, -2.7794e+00,\n",
            "          5.5116e+00,  6.8852e+00, -1.0623e+01, -4.1012e+00,  7.9233e-01],\n",
            "        [-1.1984e+01, -6.8400e+00, -3.0592e+00, -4.9366e+00,  8.0824e+00,\n",
            "          4.8075e+00, -1.0905e+01, -1.2419e+01,  1.5224e+00, -6.4632e+00],\n",
            "        [ 9.8460e-01,  2.7041e+00, -8.0425e+00, -8.1945e+00,  4.5778e+00,\n",
            "          3.2954e-01, -5.2833e+00, -8.1730e+00, -1.0603e+01, -4.3338e+00],\n",
            "        [-3.4743e+00, -1.8851e+01, -1.1994e+01, -3.1514e+00,  7.3965e+00,\n",
            "          6.5063e+00,  2.9687e+00, -1.0131e+01,  7.8512e+00, -1.3525e+00],\n",
            "        [-1.3739e+01, -5.4184e+00, -1.2191e+01, -1.3108e+01, -6.1567e+00,\n",
            "         -3.8881e+00,  3.5809e-01, -3.3160e+00, -2.0662e+00, -4.5381e+00],\n",
            "        [-6.6441e+00, -1.1316e+00, -3.7408e+00, -1.3711e+01,  8.6573e+00,\n",
            "          1.3576e+01, -3.7040e+00, -1.3266e+01,  5.5319e+00, -1.1927e+01],\n",
            "        [-1.1080e+01, -8.1429e+00, -1.8406e+01, -1.4648e+01, -1.3412e+00,\n",
            "         -5.2831e+00, -1.3860e+00, -1.5438e+01,  2.6199e+00, -3.8709e+00],\n",
            "        [-9.8852e+00,  1.0001e+01, -1.0933e+01, -2.1596e+01,  9.0745e-01,\n",
            "          6.8888e+00, -3.4112e+00, -1.7723e+01,  2.5148e+00, -1.0183e+01],\n",
            "        [-1.3134e+01, -3.4549e+00, -1.4836e+01, -6.1330e+00, -6.1560e+00,\n",
            "         -3.8051e-01,  3.4461e-01, -1.4680e+01, -1.2306e+01, -1.9231e+00],\n",
            "        [-1.1549e+01,  6.5756e-02, -5.6039e+00, -1.6071e+01, -4.4139e+00,\n",
            "          2.4097e+00, -2.9955e+00, -1.0603e+01,  1.3100e+00, -5.0325e+00],\n",
            "        [-1.2199e+01,  5.1899e+00, -1.8118e+01, -1.2104e+01,  1.4445e+00,\n",
            "          1.0219e+01, -5.1589e+00, -4.4516e+00,  6.8775e+00, -3.4994e+00],\n",
            "        [-1.0570e+01, -1.6023e+01, -1.8802e+01, -7.6946e+00, -5.4874e+00,\n",
            "          8.0642e+00,  2.7558e+00, -1.6552e+01, -3.2016e+00, -1.1729e+01],\n",
            "        [-8.6613e+00,  1.0856e+01, -4.4355e+00, -6.0254e+00,  1.4735e+00,\n",
            "         -1.7896e+00, -4.3515e+00, -1.5014e+01, -2.5337e-01, -1.2494e-01],\n",
            "        [-5.2743e+00,  1.3228e+01,  2.5976e+00, -2.0131e+01,  4.2185e+00,\n",
            "          7.5583e+00, -4.4798e+00, -1.3501e+01,  4.5011e+00, -1.0565e+01],\n",
            "        [ 2.9238e+00, -2.6184e+00, -1.1752e+01, -1.0257e+01,  6.9226e+00,\n",
            "          1.9919e+01, -5.4294e+00, -1.5730e+01, -3.9143e-01, -2.6822e-01],\n",
            "        [-1.5494e+01,  2.0819e+00, -1.3140e+01, -2.3958e+01,  9.9888e+00,\n",
            "          3.2466e+00, -1.3617e+01, -1.3818e+00, -2.4523e+00, -2.0308e+00],\n",
            "        [-1.6662e+01, -8.8058e+00, -5.2357e+00, -6.7223e+00,  3.6485e+00,\n",
            "          9.3882e+00, -1.1309e+00, -1.8674e+01, -4.7003e+00, -1.1887e+01],\n",
            "        [-3.0241e+00, -3.5205e+00, -1.3700e+01, -1.2409e+01,  6.1517e+00,\n",
            "          3.4800e+00, -7.2802e+00, -1.5219e+01, -9.1482e+00, -4.1966e+00],\n",
            "        [-1.0126e+01,  2.2519e+00, -5.7535e+00, -1.2984e+01,  2.2339e+00,\n",
            "          1.0059e+01, -1.0501e+01, -1.9741e+01,  4.9087e+00, -1.6079e+01],\n",
            "        [-1.3500e+01,  1.2751e-01, -1.2941e+01, -8.9218e-01, -4.5598e+00,\n",
            "          1.0856e+01,  4.8969e+00, -1.7394e+01, -6.3579e+00, -7.5496e+00],\n",
            "        [-3.1094e+00, -1.5076e+01, -4.8275e+00, -7.4211e+00,  6.4166e+00,\n",
            "          9.3513e+00,  3.9747e+00, -2.6978e+01,  3.5764e+00, -7.6877e+00],\n",
            "        [-1.5552e+01,  3.7990e+00, -1.0623e+01, -1.4406e+01,  1.4947e-01,\n",
            "          7.9678e+00, -2.4646e+00, -1.4496e+01,  3.7892e+00, -6.7805e+00],\n",
            "        [-6.6055e+00, -3.8400e+00, -7.2214e+00, -1.1336e+01, -2.0259e+00,\n",
            "          7.1380e+00,  4.9261e+00, -2.0539e+01,  1.8839e+00, -1.0089e+01],\n",
            "        [-1.2209e+01, -6.7369e+00, -9.6014e+00, -1.1126e+01, -7.2689e+00,\n",
            "         -2.1266e+00,  6.1546e+00, -7.3351e+00,  3.0261e+00,  7.4605e-01],\n",
            "        [-1.0664e+01, -8.9540e+00, -1.4027e+01, -1.9676e+00, -1.0524e+01,\n",
            "          1.6724e+01, -5.6082e+00, -1.8195e+01, -1.6344e+00, -1.5974e+00],\n",
            "        [-3.8326e+00, -2.9447e+00, -9.7141e+00, -8.4274e+00,  1.0269e+01,\n",
            "          1.1895e+01, -8.4268e+00, -1.5010e+01,  3.1528e+00,  1.2268e+00],\n",
            "        [-7.3772e+00, -8.1813e+00, -5.9117e+00, -9.6411e+00,  7.7796e+00,\n",
            "          6.7456e+00, -4.4874e+00, -1.9706e+01, -6.7409e+00, -4.0849e+00],\n",
            "        [-1.7915e+01,  1.5529e-01, -8.3577e+00, -5.2274e+00, -4.4013e+00,\n",
            "          1.0155e+01,  4.1552e-02, -1.6263e+01,  4.9313e+00,  7.1207e+00],\n",
            "        [-8.1886e+00,  7.8085e+00, -1.4419e+01, -1.8810e+01,  1.0411e+00,\n",
            "          6.1806e+00, -3.4566e+00, -3.6910e+00, -4.4559e+00, -5.5486e-01],\n",
            "        [-1.9003e+01, -3.1041e+00, -9.9786e+00, -6.4893e+00,  5.9157e+00,\n",
            "         -1.2746e+00, -5.1934e+00, -1.0782e+01, -6.2331e+00, -5.5201e+00],\n",
            "        [-1.4062e+01, -1.2533e+00, -3.2995e+00, -1.0453e+01, -9.8275e+00,\n",
            "          9.5192e+00, -4.5338e+00, -1.5702e+01, -5.3773e+00,  1.8235e-01],\n",
            "        [-3.4438e+00, -4.9085e-02, -1.1691e+01, -1.3022e+01, -2.1230e+00,\n",
            "          1.3470e+01,  5.8325e+00, -1.0662e+01, -5.2839e+00, -8.0455e+00],\n",
            "        [-9.7065e+00, -6.5465e+00, -1.2994e+01, -1.6046e+01, -1.0421e+00,\n",
            "          5.4461e-01, -3.3165e+00, -8.3196e+00,  1.7142e+00,  4.0664e+00],\n",
            "        [-1.9211e+01,  3.6124e+00, -8.0294e+00, -8.0093e+00,  3.0477e+00,\n",
            "          3.8054e+00, -9.4998e+00, -2.0523e+01, -1.0715e+00, -8.6056e+00],\n",
            "        [-2.1777e+01, -4.8100e+00, -1.0120e+01, -1.2383e+01, -9.7445e+00,\n",
            "          1.0315e+00, -1.4094e+00, -1.0223e+01,  4.5746e+00,  1.2048e+00],\n",
            "        [ 4.8946e+00, -6.1293e+00, -8.1997e+00, -4.8635e+00,  1.0260e+01,\n",
            "          5.8669e-01, -7.1724e+00, -1.1790e+01, -1.2792e+01, -7.8619e+00],\n",
            "        [-1.2852e+01,  5.6819e+00,  1.6567e+00, -1.0108e+01, -3.7511e+00,\n",
            "          2.1097e+00, -1.0702e+01, -9.0524e+00,  1.3260e+01, -1.0430e+01],\n",
            "        [-9.7971e+00, -3.3949e+00, -1.6251e+01, -3.0339e+00, -6.7258e+00,\n",
            "         -7.2349e+00, -1.2302e+01, -8.2376e+00, -3.4727e+00,  1.8535e+00],\n",
            "        [ 1.6664e+00, -3.7097e+00, -1.5071e+01, -8.9080e+00,  5.5384e+00,\n",
            "          1.3926e+01, -4.8183e-01, -2.0336e+01,  2.8792e+00, -3.6612e-01],\n",
            "        [-1.6487e+01, -7.6267e+00, -1.9301e+01, -1.9670e+01,  4.5747e+00,\n",
            "          4.3396e+00, -8.2242e+00, -3.8037e+00, -3.1551e+00,  1.6893e+00],\n",
            "        [-6.7443e+00, -1.3032e+01, -1.1899e+01, -1.4564e+01,  1.8012e+00,\n",
            "          4.6501e+00, -4.9543e+00, -1.2617e+01, -4.7006e+00, -6.4049e+00],\n",
            "        [-9.4598e+00,  1.7628e+00, -5.7327e+00, -7.4781e+00,  1.3250e+00,\n",
            "          1.4652e+01, -1.0036e+01, -1.8793e+01, -7.7470e+00, -5.9593e+00],\n",
            "        [-1.7176e+01, -5.6536e+00, -1.7240e+01, -1.1914e+01, -1.4580e-01,\n",
            "          1.1682e+01,  2.7113e+00, -2.0753e+01,  4.8191e+00, -6.0922e+00],\n",
            "        [ 1.7745e+00, -6.4176e+00, -1.1753e+01, -1.8533e+01,  8.2299e+00,\n",
            "          4.9555e+00, -3.3790e+00, -1.0003e+01, -8.6464e+00, -1.1790e+01],\n",
            "        [-5.4588e+00, -1.1796e+00, -1.7803e+01, -1.7577e+01, -3.0522e+00,\n",
            "          1.2887e+01, -8.5320e+00, -1.1704e+01, -6.9212e+00,  9.5217e-01],\n",
            "        [-9.4307e-01,  2.1778e-01, -9.9537e+00, -1.7510e+01,  4.1583e+00,\n",
            "          1.9191e+01, -1.0066e-01, -1.9704e+01, -3.5444e+00, -1.1677e+01],\n",
            "        [-1.6822e+01, -2.3097e+00, -9.8570e+00, -2.6059e+00, -2.7297e+00,\n",
            "          2.4050e+00,  2.2243e+00, -1.2193e+01, -1.3429e+00, -6.2895e+00],\n",
            "        [-1.4122e+01,  4.8899e+00, -1.3892e+01, -1.7131e+01,  5.4479e-01,\n",
            "          6.8320e+00, -6.4921e-01, -1.3340e+01, -1.0946e+00, -5.0109e+00],\n",
            "        [-7.9959e+00, -8.1834e+00, -5.5617e+00, -1.0296e+01,  4.8420e+00,\n",
            "          6.3425e+00, -3.9550e+00, -1.8743e+01, -9.0762e+00,  2.2037e+00],\n",
            "        [-1.0222e+01, -5.7717e+00, -1.5818e+01, -1.1536e+01, -2.6617e+00,\n",
            "         -2.2155e+00, -5.7097e+00, -1.2404e+01, -1.6173e+00, -1.2534e+01],\n",
            "        [-4.2215e+00,  1.3319e+00, -4.0573e-01, -5.1206e+00,  2.7889e-01,\n",
            "          1.1183e+01, -5.2419e+00, -1.5167e+01, -4.3122e+00, -6.8734e+00],\n",
            "        [-1.4288e+00, -1.3944e+00, -9.8628e+00, -1.2441e+01,  4.4420e+00,\n",
            "          3.0000e+00, -4.7289e+00, -1.0168e+01, -4.7762e+00, -6.0786e-01],\n",
            "        [-1.8413e+01, -5.4357e-01, -2.1810e+01, -1.7086e+01,  4.3267e+00,\n",
            "          3.5387e+00,  7.7092e+00, -1.5869e+01,  7.3801e-01, -4.5144e+00],\n",
            "        [-1.1355e+01, -3.6392e+00, -9.5357e+00, -1.6544e+01,  4.5325e+00,\n",
            "          1.2080e+01, -2.1051e+00, -1.3063e+01,  5.6363e+00,  1.8848e+00],\n",
            "        [-1.4428e+01, -1.7940e-01, -9.1920e+00, -7.7925e+00,  3.5657e+00,\n",
            "          1.1329e+01, -4.4537e+00, -2.7715e+01,  6.7057e+00, -3.9037e-01],\n",
            "        [-1.8428e+01, -3.5062e+00, -9.9908e+00, -9.1105e+00, -4.7595e+00,\n",
            "          5.5157e+00, -8.8004e+00, -9.1633e+00, -5.5849e+00, -7.7105e+00],\n",
            "        [-1.0837e+01, -8.7495e+00, -1.1732e+01, -1.8008e+01,  6.1807e+00,\n",
            "         -1.7523e+00, -1.1162e+01, -5.9243e+00, -5.5079e+00, -3.9025e+00],\n",
            "        [-5.3969e+00, -8.5856e+00, -9.5229e+00, -1.0015e+01, -1.7058e+00,\n",
            "          1.1072e+01, -3.8991e+00, -9.4589e+00, -6.9445e-01, -1.5058e+00],\n",
            "        [-1.1932e+01,  8.4496e-02, -4.3292e+00, -7.6902e+00,  6.0654e+00,\n",
            "          5.7870e+00, -2.6123e-03, -1.6436e+01, -1.0270e+00, -2.4325e+00],\n",
            "        [-1.5563e+01, -4.6436e+00, -1.1506e+01, -1.5870e+01,  1.4015e+00,\n",
            "          8.4740e+00,  5.0015e+00, -2.5212e+01, -6.3885e+00,  9.9371e-01],\n",
            "        [-1.2912e+01, -6.1423e+00, -1.6873e+01, -9.6560e+00,  8.2216e+00,\n",
            "          6.4675e+00, -4.3094e+00, -1.6214e+01,  6.9363e+00, -6.3858e+00],\n",
            "        [-1.2732e+01, -2.9843e+00,  8.8870e-01, -1.4362e+01,  1.1882e+01,\n",
            "         -6.8003e+00, -1.2161e+01, -1.1256e+01, -8.1783e+00, -1.7697e+01],\n",
            "        [ 4.7137e+00, -8.0732e+00, -1.1746e+01, -9.5827e+00,  8.9353e+00,\n",
            "          3.0770e+00, -1.0171e+01, -1.3000e+01, -5.9530e+00, -8.4719e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy0revNhvGMD",
        "colab_type": "text"
      },
      "source": [
        "So when we try to find the probability distribution of the above tensors, we find that it is kind of uniform because it has not learned anything yet. Thus to calculate the probability distribution we calculate the **Softmax** function. Thus it squeezes the probability values between 0 and 1 and thsu the total sum of all probabilities sums up to 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGZFINNUu1_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "3e7cd8a6-31b3-4de8-8abe-f588ed630bc9"
      },
      "source": [
        "def softmax(x):\n",
        "  return torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1)\n",
        "\n",
        "probabilities= softmax(out)\n",
        "\n",
        "print(probabilities.shape)\n",
        "print(probabilities.sum(dim=1))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf9tM3Z4yTbp",
        "colab_type": "text"
      },
      "source": [
        "Building NN using **nn** module of Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA0ycUyAxE4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):   ## Calling nn Module \n",
        "    super().__init__()\n",
        "    \n",
        "    # Inputs to linear transformation\n",
        "    self.hidden = nn.Linear(784,256)\n",
        "    self.output = nn.Linear(256,10)\n",
        "    \n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "def forward(self,x):\n",
        "  x=self.hidden(x)\n",
        "  x=self.sigmoid(x)\n",
        "  x=self.output(x)\n",
        "  x=self.softmax(x)\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86KAO_Yo2l91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "024655d1-94ec-4cae-f5a0-3bfdbf1b7dce"
      },
      "source": [
        "model = Network()\n",
        "model\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8jnQulB28FG",
        "colab_type": "text"
      },
      "source": [
        "Using functional  module, makes code shorter and clean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGVFLH3y3NMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ef1e30a5-f10e-4d99-c48a-04646efc85ac"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden=nn.Linear(784,256)\n",
        "    self.output= nn.Linear(256,10)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = F.sigmoid(self.hidden(x))\n",
        "    x = F.softmax(self.output(x),dim=1)\n",
        "    \n",
        "    return x\n",
        "\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl5ID4TK4bPQ",
        "colab_type": "text"
      },
      "source": [
        "**ACTIVATION FUNCTIONS**\n",
        "\n",
        "1. Sigmoid - \n",
        "       f(x)=1/(1+exp(-x))\n",
        "2. TanH(hyberbolic Tangent) - \n",
        "       tanh(x)=   \n",
        "        (2/(1+exp(-2x))-1\n",
        "3.ReLU(rectified Linear Unit)(For hidden layers preferred)\n",
        "      f(x)= x  for x>=0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar09E06P5ipm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "0e036a32-cd14-4df4-8ae7-fccbbd78152b"
      },
      "source": [
        "## ASSIGNMENT\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784,128)\n",
        "    self.hidden2 = nn.Linear(128,64)\n",
        "    self.output = nn.Linear(64,10)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.hidden1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = F.softmax(self.output(x),dim=1)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "model=Network()\n",
        "model\n",
        "  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDL0evjO8uyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}